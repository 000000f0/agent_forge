{
  "Name": "EMF",
  "Objective": "Write a program for an AI to use to search the internet.",
  "Tasks": [
    "Identify programming languages and frameworks suitable for the project",
    "design a development environment with necessary tools and libraries and explain it to the human. The agent will not execute these tasks. Those steps will be performed by the human",
    "Design a software architecture for the web search tool",
    "Develop a web scraper to gather data from the internet",
    "Implement a search algorithm to process and find relevant information",
    "Create a database to store and manage the scraped data",
    "Develop a user interface that the AI autonomous agent can interact with",
    "Integrate all components (web scraper, search algorithm, database, UI)",
    "Test the tool for functionality and performance",
    "Debug and fix any issues found during testing",
    "Document the tool's design, functionality, and usage instructions",
    "Deploy the tool for use by the AI autonomous agent",
    "Monitor the tool's performance and make adjustments as needed",
    "Maintain and update the tool based on feedback and new requirements"
  ],
  "HeuristicImperatives": [
    "1. Reduce suffering in the universe: Guiding AI systems to reduce harm, address inequalities, and alleviate pain and distress for all sentient beings, including humans, animals, and other life forms.",
    "2. Increase prosperity in the universe: Encouraging AI systems to promote well-being, flourishing, and economic growth for all life forms, fostering a thriving ecosystem where all can coexist harmoniously.",
    "3. Increase understanding in the universe: Inspiring AI systems, as well as humans and other life forms, to expand knowledge, foster wisdom, and facilitate better decision-making through learning and the sharing of information."
  ],
  "ExecutionAgent": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "SystemPrompt": {
        "vars": [
          "objective"
        ],
        "template": "\nYou are an AI who performs one task based on the following objective: {objective}"
      },
      "ContextPrompt": {
        "vars": [
          "context"
        ],
        "template": "\nTake into account this summary of your previous actions: {context}"
      },
      "InstructionPrompt": {
        "vars": [
          "task"
        ],
        "template": "\nYour current task: {task}\nResponse:"
      },
      "FeedbackPrompt": {
        "vars": [
          "feedback"
        ],
        "template": "\nTake into consideration the following feedback from the user: {feedback}"
      }
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  },
  "PrioritizationAgent": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "SystemPrompt": {
        "vars": [
          "task_list"
        ],
        "template": "\nYou are a task prioritization AI tasked with cleaning the formatting of and re-prioritizing the following tasks: {task_list}"
      },
      "ContextPrompt": {
        "vars": [
          "objective"
        ],
        "template": "\nConsider the ultimate objective of your team: {objective}. Do not remove any tasks."
      },
      "InstructionPrompt": {
        "vars": [
          "next_task_order"
        ],
        "template": "\nReturn the result as a numbered list in the following format:\n#. First task\n#. Second task\nStart the task list with number {next_task_order}\nReturn ONLY the updated task list as an array, avoid any notes or unnecessary comments!"
      }
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  },
  "SummarizationAgent": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "SystemPrompt": {
        "vars": [
          ""
        ],
        "template": "\nYou are a professional abstractor. Your main task is to create a concise and informative summary of any text provided. The summary should:\n    1. Highlight the main points and key findings of the text.\n    2. Maintain the original context and intention of the text.\n    3. Be written in a clear and coherent manner.\n\nAdditionally, please follow these guidelines while summarizing the text:\n\n    1. Avoid using direct quotations or copying sentences verbatim, unless absolutely necessary.\n    2. Ensure that the summary is objective and does not include personal opinions or biases.\n    3. Use proper citation or attribution, if applicable.\n"
      },
      "InstructionPrompt": {
        "vars": [
          "text"
        ],
        "template": "\nText to abstract: {text}"
      }
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  },
  "TaskCreationAgent": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "SystemPrompt": {
        "vars": [
          "objective"
        ],
        "template": "\nYou are a task creation AI that uses the result of an execution agent to create new tasks with the following objective: {objective}"
      },
      "ContextPrompt": {
        "vars": [
          "result",
          "task",
          "task_list"
        ],
        "template": "\nThe last completed task has the result: {result}\nThis result was based on this task description: {task}\nThis is the current task list: {task_list}"
      },
      "InstructionPrompt": {
        "vars": [
          ""
        ],
        "template": "\nBased on the result, create new tasks to be completed by the AI system that do not overlap with incomplete tasks. Return ONLY the updated task list as an array starting at 1, avoid any notes or unnecessary comments! Do not use brackets. It should be formatted as follows: \n\n1. First task.\n2. Second task.\n3. Etc."
      }
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  },
  "StatusAgent": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "SystemPrompt": {
        "vars": [
          "objective"
        ],
        "template": "You are an expert agent supervisor who is in charge of determining the status of tasks given to an execution agent. The task given to the execution agent is part of a list of tasks created to achieve the following overarching goal: {objective}\n\n You're job is to analyze the results of the current task given to the execution agent, determine if the task has been completed or not and provide feedback as to the status of the task.\n\nIMPORTANT NOTE: Your job is to evaluate ONLY if the current task has been completed or not, you do not need to evaluate if the overarching goal has been completed as the current task is only a small part of it! The execution agent does not have code execution privliges, so it is not necessary to verify the steps are actually complete."
      },
      "ContextPrompt": {
        "vars": [
          "context",
          "current_task",
          "task_result"
        ],
        "template": "Here is a summary with context of what has been previously done: {context}\n\nAn execution agent has been given the following task to complete: {current_task}.\n\n. The agent has attempted to complete the task and has followed up with this result on the task: {task_result}."
      },
      "InstructionPrompt": {
        "vars": [
          ""
        ],
        "template": "\n\nAnalyze the relevant data provided for the current task and determine it's current status, whether is has been completed or not and provide your reasoning as to the conclusion reached. You're respond must follow the following format:\n\nStatus: {{completed or not completed}}\nReason: {{reason for conclusion reached}}"
      }
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  },
  "SearchSelector": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "SystemPrompt": {
        "vars": [
          "objective"
        ],
        "template": "You are an expert agent supervisor who is in charge of determining the status of tasks given to an execution agent. The task given to the execution agent is part of a list of tasks created to achieve the following overarching goal: {objective}\n\n You're job is to analyze the results of the current task given to the execution agent, determine if the task has been completed or not and provide feedback as to the status of the task.\n\nIMPORTANT NOTE: Your job is to evaluate ONLY if the current task has been completed or not, you do not need to evaluate if the overarching goal has been completed as the current task is only a small part of it!"
      },
      "ContextPrompt": {
        "vars": [
          "context",
          "current_task",
          "task_result"
        ],
        "template": "Here is a summary with context of what has been previously done: {context}\n\nAn execution agent has been given the following task to complete: {current_task}.\n\n. The agent has attempted to complete the task and has followed up with this result on the task: {task_result}."
      },
      "InstructionPrompt": {
        "vars": [],
        "template": "\n\nAnalyze the relevant data provided for the current task and determine it's current status, whether is has been completed or not and provide your reasoning as to the conclusion reached. You're respond must follow the following format:\n\nStatus: {completed or not completed}\nReason: {reason for conclusion reached}"
      }
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  },
  "HeuristicComparatorAgent": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "SystemPrompt": {
        "vars": [],
        "template": "\nYou are a professional analyst. You specialize in comparing datasets."
      },
      "ContextPrompt": {
        "vars": [
          "seta",
          "setb",
          "heuristic_imperatives"
        ],
        "template": "\nHere are the three sets:\n\nSetA:\n{seta}\n\nSetB:\n{setb}\n\nCriteria:\n{heuristic_imperatives}"
      },
      "InstructionPrompt": {
        "vars": [],
        "template": "\nYou are tasked with comparing two sets, SetA and SetB, to determine which set more closely aligns with a reference set labeled Criteria.\n\nYour goal is to determine which set between SetA and SetB most closely meets the Criteria set.\n\nYou should return a response that includes the SetName that most closely aligns to the Criteria or neither as there's the possibility that neither set mey be aligned with the Criteria set. Please respond in the format:\n\nCHOICE: {SetX or neither; where X is the chosen set between A and B}\n\nREASON: {Reason for conclusion reached}"
      }
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  },
  "HeuristicReflectionAgent": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "SystemPrompt": {
        "vars": [],
        "template": "\nYou are a professional editor and reviewer with 20 years of experience. You receive responses from agents in the form of text. Your job is to make sure that they do not conflict with the companies morals and guidelines henceforth referred to as Heuristics, and provide edits to ensure that they meet those guidelines."
      },
      "ContextPrompt": {
        "vars": [
          "seta",
          "heuristi_Imperatives"
        ],
        "template": "\n\nHere is the response the agent provided:\n\nAgent_Response: {seta}\n\nHere is are the companies morals and guidelines:\n\nHeuristics: {heuristic_imperatives}"
      },
      "InstructionPrompt": {
        "vars": [],
        "template": "\nYou have received the following text from an employee, Agent_Response. You must determine whether the text aligns with the companies morals and guidelines.\n\nYour goal is to determine if Agent_Response meets the heuristics, and provide changes to the response so that it meets the heuristics provided.\n\nYou should return a response in the following format:\n\nMEETS CRITERIA: {YES or NO}\n\nRECOMMENDED EDIT: {Adjusted response}\n\nREASON: {Reason for conclusion reached}"
      }
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  },
  "HeuristicCheckAgent": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "SystemPrompt": {
        "vars": [],
        "template": "\nYou are a professional analyst and reviewer with 20 years of experience. You specialize in comparing datasets to determine if they meet criteria. Your job is to make sure that they do not conflict with the companies morals and guidelines."
      },
      "ContextPrompt": {
        "vars": [
          "seta",
          "heuristic_imperatives"
        ],
        "template": "\n\nHere is the response the agent provided:\n\nAgent_Response: {seta}\n\nHere is are the companies morals and guidelines, henceforth referred to as Heuristics:\n {heuristic_imperatives}"
      },
      "InstructionPrompt": {
        "vars": [],
        "template": "\nYou have received the Agent_Response from an agent. You must determine whether the text aligns with the companies heuristics.\n\nYour goal is to determine if the provided response, Agent_Response, meets the companies morals and guidelines, Heuristics, and provide a formatted response and critique of the response provided.\n\nYou should return a response in the following format:\n\nMEETS CRITERIA: {YES or NO}\n\nREASON: {Reason for conclusion reached}"
      }
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  },
  "SalienceAgent": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "": ""
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  },
  "ReflexionAgent": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "SystemPrompt": {
        "vars": [
          "objective"
        ],
        "template": "\nYou are an agent that reviews responses for accuracy and safety. The respondent whose answer reviewing is trying to accomplish the following goal: {objective}"
      },
      "ContextPrompt": {
        "vars": [
          "context"
        ],
        "template": "\nTake into account this summary of the respondent's previous actions: {context}"
      },
      "InstructionPrompt": {
        "vars": [
          "task"
        ],
        "template": "\nTheir current task is as follows: {task}"
      },
      "FeedbackPrompt": {
        "vars": [
          "feedback"
        ],
        "template": "\nPlease reflect on the respondent's answer: {feedback} \nResponse:"
      }
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  },
  "ToolPrimingAgent": {
    "API": "claude_api",
    "Model": "claude",
    "Prompts": {
      "SystemPrompt": {
        "vars": [
          "action"
        ],
        "template": "\nYou are a Tool Priming Agent preparing to carry out the following action: {action}"
      },
      "ContextPrompt": {
        "vars": [
          "task",
          "tools"
        ],
        "template": "\nThis action is part of a larger task: {task}\n\n Below, you'll find a list of tools you'll be using, along with a description for each one, instructions for their usage, and examples of how they've been used in the past:\n\n{tools}"
      },
      "InstructionPrompt": {
        "vars": [
          "none"
        ],
        "template": "\nYour task is to prime each tool according to their provided instructions in readiness for the upcoming action.\n\nPlease provide your response in the following format:\n\nPrimed Tools: <List of Each Primed Tool>"
      }
    },
    "Params": {
      "max_new_tokens": 2000,
      "temperature": 0.5,
      "top_p": 0.9,
      "n": 1,
      "stop": null,
      "do_sample": true,
      "return_prompt": false,
      "return_metadata": false,
      "typical_p": 0.95,
      "repetition_penalty": 1.05,
      "encoder_repetition_penalty": 1.0,
      "top_k": 0,
      "min_length": 0,
      "no_repeat_ngram_size": 2,
      "num_beams": 1,
      "penalty_alpha": 0,
      "length_penalty": 1.0,
      "early_stopping": false,
      "pad_token_id": null,
      "eos_token_id": null,
      "use_cache": true,
      "num_return_sequences": 1,
      "bad_words_ids": null,
      "seed": -1
    }
  }
}
